{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, GRU, Dropout\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      0  - Awww, c'est un bummer. Tu devrais avoir davi...\n",
      "1      0  Est contrarié qu'il ne puisse pas mettre à jou...\n",
      "2      0  J'ai plongé plusieurs fois pour la balle. A ré...\n",
      "3      0  Tout mon corps a des démangeaisons et comme si...\n",
      "4      0  Non, il ne se comporte pas du tout. je suis en...\n"
     ]
    }
   ],
   "source": [
    "# Importer les données\n",
    "path = './data/french_tweets.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Afficher les données\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diminuons la taille du df\n",
    "df_negative = df.loc[:50000]\n",
    "df_positive = df.loc[771628:821628]\n",
    "\n",
    "df = pd.concat([df_negative, df_positive])\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100002, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Awww, c'est un bummer. Tu devrais avoir david carr du troisième jour pour le faire. ;ré\n"
     ]
    }
   ],
   "source": [
    "print(df['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage du df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.73)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-md==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.7.0/fr_core_news_md-3.7.0-py3-none-any.whl (45.8 MB)\n",
      "     ---------------------------------------- 45.8/45.8 MB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fr-core-news-md==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.24.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\morcodou.seck\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installation de spacy et téléchargement de fr_core_news_md\n",
    "!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "import spacy\n",
    "\n",
    "nlp_spacy = spacy.load('fr_core_news_md')\n",
    "Stopwords = stopwords.words('french')\n",
    "\n",
    "def cleannig_tweet(text):\n",
    "    expanded_all = []\n",
    "    text = re.sub(r'http[s]*:?//\\S+','', text)\n",
    "    text = re.sub(r'@[\\w\\-\\.]+', '', text)\n",
    "    text = re.sub(r'[\\w\\-\\.]+@[\\w\\-\\.]+', '', text)\n",
    "    text = re.sub(r'&\\w+','', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]+', ' ', text)\n",
    "    text = re.sub(r'^\\s|\\s$', '', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text).lower()\n",
    "    \n",
    "    \n",
    "    for word in text.split():\n",
    "        expanded_all.append(contractions.fix(word))\n",
    "    text = ' '.join(expanded_all)\n",
    "    \n",
    "    \n",
    "    text = ' '.join([word for word in text.split() if word not in Stopwords])\n",
    "\n",
    "    tokens  = nlp_spacy(text)\n",
    "    text = [word.lemma_ for word in tokens]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction cleannig_tweet\n",
    "df['tweet'] = df.text.apply(func = cleannig_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Awww, c'est un bummer. Tu devrais avoir david carr du troisième jour pour le faire. ;ré\n",
      "awww bummer devoir avoir david carr troisi jour faire r\n"
     ]
    }
   ],
   "source": [
    "print(df['text'][0])\n",
    "print(df['tweet'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>- Awww, c'est un bummer. Tu devrais avoir davi...</td>\n",
       "      <td>awww bummer devoir avoir david carr troisi jou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Est contrarié qu'il ne puisse pas mettre à jou...</td>\n",
       "      <td>contrari pouvoir mettre jour facebook maignant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>J'ai plongé plusieurs fois pour la balle. A ré...</td>\n",
       "      <td>plong plusieurs fois balle avoir r ussi conomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tout mon corps a des démangeaisons et comme si...</td>\n",
       "      <td>tout corps avoir mangeaison comme si taire feu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Non, il ne se comporte pas du tout. je suis en...</td>\n",
       "      <td>non comporte tout col r pourquoi ici parce pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  - Awww, c'est un bummer. Tu devrais avoir davi...   \n",
       "1      0  Est contrarié qu'il ne puisse pas mettre à jou...   \n",
       "2      0  J'ai plongé plusieurs fois pour la balle. A ré...   \n",
       "3      0  Tout mon corps a des démangeaisons et comme si...   \n",
       "4      0  Non, il ne se comporte pas du tout. je suis en...   \n",
       "\n",
       "                                               tweet  \n",
       "0  awww bummer devoir avoir david carr troisi jou...  \n",
       "1  contrari pouvoir mettre jour facebook maignant...  \n",
       "2  plong plusieurs fois balle avoir r ussi conomi...  \n",
       "3     tout corps avoir mangeaison comme si taire feu  \n",
       "4  non comporte tout col r pourquoi ici parce pou...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichons le jeu de données\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vectorisation des tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorison avec Tokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Nombre de mots\n",
    "nbr_word_unique = len(set(\" \".join(df.tweet).split()))\n",
    "\n",
    "# Initialiser le modèle Tokenizer\n",
    "tokenizer = Tokenizer(num_words = nbr_word_unique, split=' ')\n",
    "\n",
    "# Entrainer les données\n",
    "tokenizer.fit_on_texts(df['tweet'].values)\n",
    "\n",
    "# Vectoriser\n",
    "vect_array = tokenizer.texts_to_sequences(df['tweet'].values)\n",
    "\n",
    "# Padding\n",
    "vect_array = pad_sequences(vect_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le tokenizer en JSON\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open('french_tokenizer.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(tokenizer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39476"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Le nombre de mot uniques dans les tweets\n",
    "nbr_word_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définission des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installons keras-tuner\n",
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Séparation des données en train, test et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Labels\n",
    "y = df.label.values\n",
    "\n",
    "# Splitter en train et test\n",
    "x_train, x_test, y_train, y_test = train_test_split(vect_array, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitter validation et test\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définissons l'opitmizer\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidir_lstm_model_builder(hp):\n",
    "    emb_dimention = hp.Int('emb_dimention', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones_l2 = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    \n",
    "    Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    bidir_lstm_model=Sequential()\n",
    "    bidir_lstm_model.add(Embedding(nbr_word_unique, emb_dimention, input_length=vect_array.shape[1]))\n",
    "    bidir_lstm_model.add(Bidirectional(LSTM(nbr_neurones, return_sequences=True)))\n",
    "    if dropout :\n",
    "        bidir_lstm_model.add(Dropout(0.4))\n",
    "    bidir_lstm_model.add(Bidirectional(LSTM(nbr_neurones_l2)))\n",
    "    if dropout: \n",
    "        bidir_lstm_model.add(Dropout(0.4))\n",
    "    bidir_lstm_model.add(Dense(1,activation='sigmoid'))\n",
    "    bidir_lstm_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return bidir_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidir_gru_model_builder(hp):\n",
    "    emb_dimention = hp.Int('emb_dimention', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones_l2 = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    \n",
    "    Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    bidir_gru_model=Sequential()\n",
    "    bidir_gru_model.add(Embedding(nbr_word_unique, emb_dimention, input_length=vect_array.shape[1]))\n",
    "    bidir_gru_model.add(Bidirectional(GRU(nbr_neurones, return_sequences=True)))\n",
    "    if dropout :\n",
    "        bidir_gru_model.add(Dropout(0.4))\n",
    "    bidir_gru_model.add(Bidirectional(GRU(nbr_neurones_l2)))\n",
    "    if dropout: \n",
    "        bidir_gru_model.add(Dropout(0.4))\n",
    "    bidir_gru_model.add(Dense(1,activation='sigmoid'))\n",
    "    bidir_gru_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return bidir_gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model_builder(hp):\n",
    "    emb_dimention = hp.Int('emb_dimention', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones_l2 = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    \n",
    "    Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    lstm_model=Sequential()\n",
    "    lstm_model.add(Embedding(nbr_word_unique, emb_dimention, input_length=vect_array.shape[1]))\n",
    "    lstm_model.add(LSTM(nbr_neurones, return_sequences=True))\n",
    "    if dropout :\n",
    "        lstm_model.add(Dropout(0.4))\n",
    "    lstm_model.add(LSTM(nbr_neurones_l2))\n",
    "    if dropout: \n",
    "        lstm_model.add(Dropout(0.4))\n",
    "    lstm_model.add(Dense(1,activation='sigmoid'))\n",
    "    lstm_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_model_builder(hp):\n",
    "    emb_dimention = hp.Int('emb_dimention', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones_l2 = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    \n",
    "    Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    gru_model=Sequential()\n",
    "    gru_model.add(Embedding(nbr_word_unique, emb_dimention, input_length=vect_array.shape[1]))\n",
    "    gru_model.add(GRU(nbr_neurones, return_sequences=True))\n",
    "    if dropout :\n",
    "        gru_model.add(Dropout(0.4))\n",
    "    gru_model.add(GRU(nbr_neurones_l2))\n",
    "    if dropout: \n",
    "        gru_model.add(Dropout(0.4))\n",
    "    gru_model.add(Dense(1,activation='sigmoid'))\n",
    "    gru_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(model_to_tune):\n",
    "    # Mettons en place un rapel d'arrêt après avoir atteint une certaine valeur\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    \n",
    "    # Instancions le tuner\n",
    "    tuner = kt.RandomSearch(\n",
    "        model_to_tune,\n",
    "        objective='val_accuracy',\n",
    "        max_trials = 2,\n",
    "        overwrite = True,\n",
    "        directory='tuners_dir',\n",
    "        project_name='intro_to_kt'\n",
    "    )\n",
    "    \n",
    "    # Exécutons la recherche des paramètres\n",
    "    tuner.search(x_train, y_train, validation_data=(x_val, y_val), epochs=3, callbacks=[stop_early])\n",
    "    \n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 47m 23s]\n",
      "val_accuracy: 0.7468000054359436\n",
      "\n",
      "Best val_accuracy So Far: 0.7468000054359436\n",
      "Total elapsed time: 01h 35m 42s\n"
     ]
    }
   ],
   "source": [
    "# Récupérons les models tunes\n",
    "print(\"bi dir lstm\")\n",
    "bidir_lstm_tuner = tune_model(bidir_lstm_model_builder)\n",
    "\n",
    "print(\"\\nbi dir gru\")\n",
    "bidir_gru_tuner = tune_model(bidir_gru_model_builder)\n",
    "\n",
    "print(\"\\nlstm\")\n",
    "lstm_tuner = tune_model(lstm_model_builder)\n",
    "\n",
    "print(\"\\n gru\")\n",
    "gru_tuner = tune_model(gru_model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construisons les modèles\n",
    "bidir_lstm_model = bidir_lstm_tuner.hypermodel.build(bidir_lstm_tuner.get_best_hyperparameters(num_trials=1)[0])\n",
    "bidir_gru_model = bidir_gru_tuner.hypermodel.build(bidir_gru_tuner.get_best_hyperparameters(num_trials=1)[0])\n",
    "lstm_model = lstm_tuner.hypermodel.build(lstm_tuner.get_best_hyperparameters(num_trials=1)[0])\n",
    "gru_model = gru_tuner.hypermodel.build(gru_tuner.get_best_hyperparameters(num_trials=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\"name\": \"bidirectional LSTM\", \"model\": bidir_lstm_model, \"score\": 0},\n",
    "    {\"name\": \"LSTM\", \"model\": lstm_model, \"score\": 0},\n",
    "    {\"name\": \"bidirectional GRU\", \"model\": bidir_gru_model, \"score\": 0},\n",
    "    {\"name\": \"GRU\", \"model\": gru_model, \"score\": 0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidirectional LSTM\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 38, 288)           11369088  \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 38, 448)           919296    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 38, 448)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 448)               1206016   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 448)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 449       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13494849 (51.48 MB)\n",
      "Trainable params: 13494849 (51.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "LSTM\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 38, 192)           7579392   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 38, 416)           1013376   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 416)               1386112   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 417       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9979297 (38.07 MB)\n",
      "Trainable params: 9979297 (38.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "bidirectional GRU\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 38, 320)           12632320  \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 38, 512)           887808    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 512)               1182720   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14703361 (56.09 MB)\n",
      "Trainable params: 14703361 (56.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "GRU\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 38, 416)           16422016  \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 38, 128)           209664    \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16730881 (63.82 MB)\n",
      "Trainable params: 16730881 (63.82 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model[\"name\"])\n",
    "    print(model[\"model\"].summary())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement et Validation des modèles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entrainement et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle bidirectional LSTM\n",
      "Epoch 1/5\n",
      "1251/1251 [==============================] - 1194s 954ms/step - loss: 0.2534 - accuracy: 0.8886 - val_loss: 0.7770 - val_accuracy: 0.7158\n",
      "Epoch 2/5\n",
      "1251/1251 [==============================] - 1169s 934ms/step - loss: 0.2001 - accuracy: 0.9120 - val_loss: 0.9172 - val_accuracy: 0.7070\n",
      "Epoch 3/5\n",
      "1251/1251 [==============================] - 1168s 933ms/step - loss: 0.1688 - accuracy: 0.9252 - val_loss: 1.1617 - val_accuracy: 0.7039\n",
      "Epoch 4/5\n",
      "1251/1251 [==============================] - 1168s 934ms/step - loss: 0.1457 - accuracy: 0.9358 - val_loss: 1.3583 - val_accuracy: 0.7064\n",
      "Epoch 5/5\n",
      "1251/1251 [==============================] - 1168s 934ms/step - loss: 0.1286 - accuracy: 0.9432 - val_loss: 1.3242 - val_accuracy: 0.7037\n",
      "313/313 [==============================] - 55s 170ms/step\n",
      "Modèle LSTM\n",
      "Epoch 1/5\n",
      "1251/1251 [==============================] - 1183s 942ms/step - loss: 0.5513 - accuracy: 0.7155 - val_loss: 0.5284 - val_accuracy: 0.7414\n",
      "Epoch 2/5\n",
      "1251/1251 [==============================] - 1249s 999ms/step - loss: 0.4454 - accuracy: 0.7918 - val_loss: 0.5401 - val_accuracy: 0.7360\n",
      "Epoch 3/5\n",
      "1251/1251 [==============================] - 1176s 940ms/step - loss: 0.3596 - accuracy: 0.8384 - val_loss: 0.6075 - val_accuracy: 0.7256\n",
      "Epoch 4/5\n",
      "1251/1251 [==============================] - 1177s 941ms/step - loss: 0.2862 - accuracy: 0.8733 - val_loss: 0.7088 - val_accuracy: 0.7133\n",
      "Epoch 5/5\n",
      "1251/1251 [==============================] - 1160s 927ms/step - loss: 0.2295 - accuracy: 0.8991 - val_loss: 0.8515 - val_accuracy: 0.7080\n",
      "313/313 [==============================] - 78s 245ms/step\n",
      "Modèle bidirectional GRU\n",
      "Epoch 1/5\n",
      "1251/1251 [==============================] - 1149s 910ms/step - loss: 0.5426 - accuracy: 0.7211 - val_loss: 0.5212 - val_accuracy: 0.7410\n",
      "Epoch 2/5\n",
      "1251/1251 [==============================] - 1107s 885ms/step - loss: 0.4377 - accuracy: 0.7964 - val_loss: 0.5346 - val_accuracy: 0.7372\n",
      "Epoch 3/5\n",
      "1251/1251 [==============================] - 1115s 891ms/step - loss: 0.3452 - accuracy: 0.8474 - val_loss: 0.6313 - val_accuracy: 0.7187\n",
      "Epoch 4/5\n",
      "1251/1251 [==============================] - 1107s 885ms/step - loss: 0.2669 - accuracy: 0.8837 - val_loss: 0.7187 - val_accuracy: 0.7081\n",
      "Epoch 5/5\n",
      "1251/1251 [==============================] - 1108s 886ms/step - loss: 0.2079 - accuracy: 0.9099 - val_loss: 0.8612 - val_accuracy: 0.7003\n",
      "313/313 [==============================] - 50s 157ms/step\n",
      "Modèle GRU\n",
      "Epoch 1/5\n",
      "1251/1251 [==============================] - 450s 356ms/step - loss: 0.5398 - accuracy: 0.7246 - val_loss: 0.5198 - val_accuracy: 0.7415\n",
      "Epoch 2/5\n",
      "1251/1251 [==============================] - 430s 343ms/step - loss: 0.4330 - accuracy: 0.7999 - val_loss: 0.5479 - val_accuracy: 0.7392\n",
      "Epoch 3/5\n",
      "1251/1251 [==============================] - 442s 353ms/step - loss: 0.3358 - accuracy: 0.8540 - val_loss: 0.6504 - val_accuracy: 0.7250\n",
      "Epoch 4/5\n",
      "1251/1251 [==============================] - 436s 349ms/step - loss: 0.2538 - accuracy: 0.8897 - val_loss: 0.7269 - val_accuracy: 0.7168\n",
      "Epoch 5/5\n",
      "1251/1251 [==============================] - 440s 352ms/step - loss: 0.1976 - accuracy: 0.9128 - val_loss: 0.9508 - val_accuracy: 0.7059\n",
      "313/313 [==============================] - 9s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "# entrainement et validation des modèles\n",
    "for model in models:\n",
    "    print(f\"Modèle {model['name']}\")\n",
    "    model['model'].fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5, batch_size=64)\n",
    "    \n",
    "    # Prédire les labels de x_val\n",
    "    y_pred = model['model'].predict(x_val)\n",
    "    \n",
    "    # Arrondir les valeurs\n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    # calculons l'accuracy\n",
    "    model['score'] = accuracy_score(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidirectional LSTM: 0.7037\n",
      "LSTM: 0.708\n",
      "bidirectional GRU: 0.7003\n",
      "GRU: 0.7059\n"
     ]
    }
   ],
   "source": [
    "# Affichons les scores et choisissons le meilleur modèle\n",
    "choosed_model = models[0]\n",
    "for model in models:\n",
    "    print(f\"{model['name']}: {model['score']}\")\n",
    "    if(model['score'] > choosed_model['score']):\n",
    "        choosed_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle choisi est :\n",
      "LSTM: 0.708\n"
     ]
    }
   ],
   "source": [
    "# Affichons le modèle choisi\n",
    "print(\"Le modèle choisi est :\")\n",
    "print(f\"{choosed_model['name']}: {choosed_model['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\morcodou.seck\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# sauvegarde du modèle\n",
    "choosed_model['model'].save(\"models/french_sentiment_analysis.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
